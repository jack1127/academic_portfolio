{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習 Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (463715, 90)\n",
      "Y_train shape =  (463715,)\n",
      "X_test shape =  (51630, 90)\n"
     ]
    }
   ],
   "source": [
    "#load packages\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Load data\n",
    "with open('data/msd_full.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "X_train = msd_data['X_train']\n",
    "X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test'].astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "print(\"X_train shape = \", X_train.shape)\n",
    "print(\"Y_train shape = \", Y_train.shape)\n",
    "\n",
    "print(\"X_test shape = \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用現有的OLS model做training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#Q1 OLS\n",
    "X_train_OLS = sm.add_constant(X_train)\n",
    "model = sm.OLS(Y_train, X_train_OLS)\n",
    "result = model.fit()\n",
    "X_test_OLS = sm.add_constant(X_test)\n",
    "Y_pred = result.predict(X_test_OLS)\n",
    "RMSE_OLS = 0;\n",
    "\n",
    "for i in range(Y_test.shape[0]):\n",
    "\tRMSE_OLS += (Y_pred[i]-Y_test[i])**2\n",
    "RMSE_OLS = RMSE_OLS/Y_test.shape[0]\n",
    "RMSE_OLS = RMSE_OLS**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS = 9.510160685594299\n",
      "[ 0.          5.30975265 -2.88088114 -1.53234348  0.05737583 -0.33952889]\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE of OLS =\", RMSE_OLS);\n",
    "print(result.params[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於題目要求OLS模型加入常數項，params的第一項為截距項，後面五項才是所要的前五個特徵參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data regularization, turn it to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_subtrain shape =  (417344, 90)\n",
      "X_valid shape =  (46371, 90)\n",
      "Y_subtrain shape =  (417344,)\n",
      "Y_valid shape =  (46371,)\n"
     ]
    }
   ],
   "source": [
    "xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "#standardize feature values\n",
    "X_train = xscaler.transform(msd_data['X_train'])\n",
    "X_test = xscaler.transform(msd_data['X_test'])\n",
    "\n",
    "y_mean = Y_train.mean()\n",
    "Y_train_keep = Y_train.copy()\n",
    "Y_test_keep = Y_test.copy()\n",
    "Y_train = Y_train - y_mean\n",
    "Y_test = Y_test - y_mean\n",
    "\n",
    "#validation is the last 10% of training, subtraining is the first 90% of training\n",
    "nvalid = int(X_train.shape[0] * 0.1)\n",
    "nsubtrain = X_train.shape[0] - nvalid\n",
    "\n",
    "X_subtrain = X_train[0:nsubtrain, :].astype('float32')\n",
    "X_valid = X_train[nsubtrain:, :].astype('float32')\n",
    "Y_subtrain = Y_train[0:nsubtrain].astype('float32')\n",
    "Y_valid = Y_train[nsubtrain:].astype('float32')\n",
    "\n",
    "Y_subtrain_keep = Y_train_keep[0:nsubtrain].astype('float32')\n",
    "Y_valid_keep = Y_train_keep[nsubtrain:].astype('float32')\n",
    "\n",
    "print(\"X_subtrain shape = \", X_subtrain.shape)\n",
    "print(\"X_valid shape = \", X_valid.shape)\n",
    "print(\"Y_subtrain shape = \", Y_subtrain.shape)\n",
    "print(\"Y_valid shape = \", Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subtrain_torch = torch.FloatTensor(X_subtrain)\n",
    "X_valid_torch = torch.FloatTensor(X_valid)\n",
    "Y_subtrain_torch = torch.FloatTensor(Y_subtrain)\n",
    "Y_valid_torch = torch.FloatTensor(Y_valid)\n",
    "Y_subtrain_torch = torch.FloatTensor(Y_subtrain_keep)\n",
    "Y_valid_torch = torch.FloatTensor(Y_valid_keep)\n",
    "X_test_torch = torch.FloatTensor(X_test)\n",
    "Y_test_torch = torch.FloatTensor(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, Xnp, Ynp):\n",
    "        'Initialization, passing Xnp and Ynp'\n",
    "        self.labels = Ynp\n",
    "        self.nobs = Xnp.shape[0]        \n",
    "        self.Xnp = Xnp\n",
    "        self.Ynp = Ynp\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.nobs\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'        \n",
    "        X = self.Xnp[index]\n",
    "        y = self.Ynp[index]\n",
    "        return X, y\n",
    "       \n",
    "subtrainset = Dataset(X_subtrain, Y_subtrain)\n",
    "validset = Dataset(X_valid, Y_valid)\n",
    "testset = Dataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtrainset len =  417344\n",
      "validset len =  46371\n",
      "testset len =  51630\n"
     ]
    }
   ],
   "source": [
    "print(\"subtrainset len = \", len(subtrainset))\n",
    "print(\"validset len = \", len(validset))\n",
    "print(\"testset len = \", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch size: torch.Size([1000, 90])\n",
      "y_batch size: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "subtrainloader = data.DataLoader(subtrainset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "X_batch, Y_batch = next(iter(subtrainloader))\n",
    "print(\"X_batch size:\", X_batch.size())\n",
    "print(\"y_batch size:\", Y_batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. MLP with Four Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照題目要求，設定每100個batch記錄一次RMSE，batch size為1000。挑出並記錄模型中最優的valid rmse的狀態，將該狀態套用在test上，以計算最終的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n"
     ]
    }
   ],
   "source": [
    "H=45\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = \"cuda\"   \n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Running on device: \", device)\n",
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(90, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, 1),\n",
    ")\n",
    "\n",
    "# convert everything to float precision. \n",
    "net = net.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return torch.sum(torch.pow((x - y), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n",
    "\n",
    "loss_fn = SSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  10001\n",
      "batch cnt =  10001\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "nepoch = 100\n",
    "batch_cnt = 0\n",
    "best_step_cnt = 0\n",
    "early_stop = 0\n",
    "best_rmse = math.inf\n",
    "    \n",
    "subtrain_rmse_list = []\n",
    "valid_rmse_list = []\n",
    "\n",
    "for epoch_id in range(0, nepoch): \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))      \n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_cnt += 1\n",
    "        best_step_cnt += 1\n",
    "        if batch_cnt % 100 == 0:\n",
    "            subtrain_pred = net(X_subtrain_torch)\n",
    "            subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            valid_pred = net(X_valid_torch)\n",
    "            valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            \n",
    "            if valid_rmse < best_rmse:\n",
    "                best_step_cnt = 0\n",
    "                best_rmse = valid_rmse\n",
    "                torch.save(net.state_dict(), './net/best_q2_H'+str(H)+'.pkl')\n",
    "        if best_step_cnt > 5000:\n",
    "            print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "            print(\"batch cnt while early stop = \", batch_cnt)\n",
    "            early_stop = 1\n",
    "            break\n",
    "    if early_stop == 1:\n",
    "        break\n",
    "print(\"batch cnt = \", batch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = list(range(len(subtrain_rmse_list)))\n",
    "plt.plot(l, subtrain_rmse_list, label='subtrain')\n",
    "plt.plot(l, valid_rmse_list, label='valid')\n",
    "plt.xlabel(\"per 100 batch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 45, test RMSE =  8.967344\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./net/best_q2_H45.pkl'))\n",
    "net.eval()\n",
    "test_pred = net(X_test_torch)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "print(\"H = 45, test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從圖形來觀察，subtrain RMSE有隨著per 100 batch增加而略微減少的趨勢，但valid RMSE沒有明顯下降，而是呈現上下波動的狀態。雖然training RMSE仍在下降，但valid RMSE卻沒有更好，繼續train會導致overfitting使得預測效果更差，因此透過early stopping的機制，提前終止迴圈並且保留最好的模型參數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. MLP with different H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調整H，重新做與Q2相同的事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  6201\n"
     ]
    }
   ],
   "source": [
    "H = 90\n",
    "batch_cnt = 0\n",
    "best_step_cnt = 0\n",
    "early_stop = 0\n",
    "best_rmse = math.inf\n",
    "\n",
    "for epoch_id in range(0, nepoch): \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))      \n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_cnt += 1\n",
    "        best_step_cnt += 1\n",
    "        if batch_cnt % 100 == 0:\n",
    "            subtrain_pred = net(X_subtrain_torch)\n",
    "            subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            valid_pred = net(X_valid_torch)\n",
    "            valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            \n",
    "            if valid_rmse < best_rmse:\n",
    "                best_step_cnt = 0\n",
    "                best_rmse = valid_rmse\n",
    "                torch.save(net.state_dict(), './net/best_q2_H'+str(H)+'.pkl')\n",
    "        if best_step_cnt > 5000:\n",
    "            print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "            print(\"batch cnt while early stop = \", batch_cnt)\n",
    "            early_stop = 1\n",
    "            break\n",
    "    if early_stop == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 90, test RMSE =  8.987108\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./net/best_q2_H90.pkl'))\n",
    "net.eval()\n",
    "test_pred = net(X_test_torch)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "print(\"H = 90, test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  6101\n"
     ]
    }
   ],
   "source": [
    "H = 180\n",
    "batch_cnt = 0\n",
    "best_step_cnt = 0\n",
    "early_stop = 0\n",
    "best_rmse = math.inf\n",
    "\n",
    "for epoch_id in range(0, nepoch): \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))      \n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_cnt += 1\n",
    "        best_step_cnt += 1\n",
    "        if batch_cnt % 100 == 0:\n",
    "            subtrain_pred = net(X_subtrain_torch)\n",
    "            subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            valid_pred = net(X_valid_torch)\n",
    "            valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "            \n",
    "            if valid_rmse < best_rmse:\n",
    "                best_step_cnt = 0\n",
    "                best_rmse = valid_rmse\n",
    "                torch.save(net.state_dict(), './net/best_q2_H'+str(H)+'.pkl')\n",
    "        if best_step_cnt > 5000:\n",
    "            print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "            print(\"batch cnt while early stop = \", batch_cnt)\n",
    "            early_stop = 1\n",
    "            break\n",
    "    if early_stop == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 180, test RMSE =  9.024058\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./net/best_q2_H180.pkl'))\n",
    "net.eval()\n",
    "test_pred = net(X_test_torch)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "print(\"H = 180, test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H = 45, test RMSE =  8.967344\n",
    "H = 90, test RMSE =  8.987108\n",
    "H = 180, test RMSE =  9.024058\n",
    "根據上述結果看來，net在H=45時表現最佳、在H=180時表現最差，這說明著對於這個資料集而言，最適當的hidden node數量很可能較接近45。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. MSL with decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照題目要求，使用Q2的模型設定，並增加decay的參數來預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer_q4 = torch.optim.SGD(net.parameters(), lr=0.00001, weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_q4(H, wd):\n",
    "    batch_cnt = 0\n",
    "    best_step_cnt = 0\n",
    "    early_stop = 0\n",
    "    best_rmse = math.inf\n",
    "    \n",
    "    for epoch_id in range(0, nepoch): \n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))      \n",
    "            net.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_q4.zero_grad()\n",
    "            outputs = net(inputs)        \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer_q4.step()\n",
    "\n",
    "            batch_cnt += 1\n",
    "            best_step_cnt += 1\n",
    "            if batch_cnt % 100 == 0:\n",
    "                subtrain_pred = net(X_subtrain_torch)\n",
    "                subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "                subtrain_rmse_list.append(subtrain_rmse)\n",
    "                valid_pred = net(X_valid_torch)\n",
    "                valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "                valid_rmse_list.append(valid_rmse)\n",
    "\n",
    "                if valid_rmse < best_rmse:\n",
    "                    best_step_cnt = 0\n",
    "                    best_rmse = valid_rmse\n",
    "                    torch.save(net.state_dict(), './net/best_q4_H'+str(H)+'_wd'+str(wd)+'.pkl')\n",
    "            if best_step_cnt > 5000:\n",
    "                print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "                print(\"batch cnt while early stop = \", batch_cnt)\n",
    "                early_stop = 1\n",
    "                break\n",
    "        if early_stop == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  5801\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  6601\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  7901\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  5801\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  6301\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  10001\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  7401\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  10701\n",
      "best step cnt while early stop =  5001\n",
      "batch cnt while early stop =  9001\n"
     ]
    }
   ],
   "source": [
    "H_q4_list = [45, 90, 180]\n",
    "wd_q4_list = [0.1, 0.2, 0.4]\n",
    "\n",
    "for h in H_q4_list:\n",
    "    for wd in wd_q4_list:\n",
    "        training_q4(h,wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 45, weight_decay = 0.1, Test RMSE = 9.044127\n",
      "H = 45, weight_decay = 0.2, Test RMSE = 9.0255\n",
      "H = 45, weight_decay = 0.4, Test RMSE = 9.05788\n",
      "H = 90, weight_decay = 0.1, Test RMSE = 9.090263\n",
      "H = 90, weight_decay = 0.2, Test RMSE = 9.104871\n",
      "H = 90, weight_decay = 0.4, Test RMSE = 9.147576\n",
      "H = 180, weight_decay = 0.1, Test RMSE = 9.13486\n",
      "H = 180, weight_decay = 0.2, Test RMSE = 9.106463\n",
      "H = 180, weight_decay = 0.4, Test RMSE = 9.155612\n"
     ]
    }
   ],
   "source": [
    "for h in H_q4_list:\n",
    "    for wd in wd_q4_list:\n",
    "        net.load_state_dict(torch.load('./net/best_q4_H'+str(h)+'_wd'+str(wd)+'.pkl'))\n",
    "        net.eval()\n",
    "        test_pred = net(X_test_torch)\n",
    "        test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "        print('H = '+str(h)+', weight_decay = '+str(wd)+', Test RMSE = '+str(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "藉由此題的結果來觀察，所有的情形表現差異不大，都有不錯的test RMSE，而在這之中，如果要挑出一個最適合的hidden nodes數量，H=45整體的表現明顯是最好的，所以應該要選H=45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5 MLP with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_d = torch.nn.Sequential(\n",
    "        torch.nn.Linear(90, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(0.5),    \n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.Linear(H, 1),\n",
    ")\n",
    "\n",
    "# convert everything to float precision. \n",
    "net_d = net_d.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer_q5 = torch.optim.Adam(net_d.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-dc0e2a047024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mnet_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = 90\n",
    "batch_cnt = 0\n",
    "best_step_cnt = 0\n",
    "early_stop = 0\n",
    "best_rmse = math.inf\n",
    "    \n",
    "subtrain_rmse_list = []\n",
    "valid_rmse_list = []\n",
    "    \n",
    "for epoch_id in range(0, nepoch):\n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        targets = targets.reshape((-1, 1))      \n",
    "        net_d.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer_q5.zero_grad()\n",
    "        outputs = net_d(inputs)        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_q5.step()\n",
    "\n",
    "        batch_cnt += 1\n",
    "        best_step_cnt += 1\n",
    "        if batch_cnt % 100 == 0:\n",
    "            subtrain_pred = net_d(X_subtrain_torch)\n",
    "            subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            valid_pred = net_d(X_valid_torch)\n",
    "            valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "\n",
    "            if valid_rmse < best_rmse:\n",
    "                best_step_cnt = 0\n",
    "                best_rmse = valid_rmse\n",
    "                torch.save(net_d.state_dict(), './net/best_q5_H'+str(H)+'.pkl')\n",
    "        if best_step_cnt > 5000:\n",
    "            print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "            print(\"batch cnt while early stop = \", batch_cnt)\n",
    "            early_stop = 1\n",
    "            break\n",
    "    if early_stop == 1:\n",
    "        break\n",
    "print(\"batch cnt = \", batch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = list(range(len(subtrain_rmse_list)))\n",
    "plt.plot(l, subtrain_rmse_list, label='subtrain')\n",
    "plt.plot(l, valid_rmse_list, label='valid')\n",
    "plt.xlabel(\"per 100 batch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這張是後來只跑出一點點的圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 90, test RMSE =  9.454007\n"
     ]
    }
   ],
   "source": [
    "net_d.load_state_dict(torch.load('./net/best_q5_H90.pkl'))\n",
    "net_d.eval()\n",
    "test_pred = net_d(X_test_torch)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "print(\"H = 90, test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(我不小心在檢查時重新按到了restart the kernel then re-run the whole notebook，且不知為何第一次10分鐘左右就能跑完的部分，跑了30分鐘只跑了600個batch(猜測原因為電腦超負荷，過熱所導致的)，最後因時間的限制下來不及重跑，只能憑印象寫下分析)\n",
    "\n",
    "由圖可知，雖然兩者的RMSE都提高一些了，但是兩者的波動幅度較為平緩，且顯然valid RMSE的效果比起沒有drop out的版本更接近subtrain RMSE(較低)，因此可以知道加入drop out機制有助於穩定資料訓練的狀況，且在test上能有較好的預測表現(test RMSE = 8.7......)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_q5(H):\n",
    "    batch_cnt = 0\n",
    "    best_step_cnt = 0\n",
    "    early_stop = 0\n",
    "    best_rmse = math.inf\n",
    "    \n",
    "    for epoch_id in range(0, nepoch): \n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))      \n",
    "            net_d.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_q5.zero_grad()\n",
    "            outputs = net_d(inputs)        \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer_q5.step()\n",
    "\n",
    "            batch_cnt += 1\n",
    "            best_step_cnt += 1\n",
    "            if batch_cnt % 100 == 0:\n",
    "                subtrain_pred = net_d(X_subtrain_torch)\n",
    "                subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "                valid_pred = net_d(X_valid_torch)\n",
    "                valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "\n",
    "                if valid_rmse < best_rmse:\n",
    "                    best_step_cnt = 0\n",
    "                    best_rmse = valid_rmse\n",
    "                    torch.save(net_d.state_dict(), './net/best_q5_H'+str(H)+'.pkl')\n",
    "            if best_step_cnt > 5000:\n",
    "                print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "                print(\"batch cnt while early stop = \", batch_cnt)\n",
    "                early_stop = 1\n",
    "                break\n",
    "        if early_stop == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-2ed21ca31f2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m360\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtraining_q5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-113-57b5b6138e1c>\u001b[0m in \u001b[0;36mtraining_q5\u001b[1;34m(H)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;31m#reshape target to two-dimensional array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "H = [20, 45, 180, 360]\n",
    "for h in H:\n",
    "    training_q5(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 20, Test RMSE = 9.26413\n",
      "H = 45, Test RMSE = 9.291512\n"
     ]
    }
   ],
   "source": [
    "H = [20, 45, 180, 360]\n",
    "for h in H:\n",
    "    net_d.load_state_dict(torch.load('./net/best_q5_H'+str(h)+'.pkl'))\n",
    "    net_d.eval()\n",
    "    test_pred = net_d(X_test_torch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "    print('H = '+str(h)+', Test RMSE = '+str(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "印象中最好的預測結果發生在H = 360，可以合理推測hidden nodes越多，drop out機制的效果越強大，當H太小的時候，0.5的drop out會使的剩餘的參數過少，因此對預測結果能力造成了反效果，比起沒有drop out的版本，預測效果反而降低了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7.L2 + L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "藉由改變z，以改變L1 loss 和 L2 loss的比例，可以算出對於此資料集而言，何種線性組合的預測效果較佳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a571b26e85ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0ml2_l1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class l2_l1_loss(torch.nn.Module):\n",
    "    def __init__(self, z):\n",
    "        super().__init__()\n",
    "        self.z = z\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return self.z * torch.sum(torch.pow((x - y), 2)) + (1 - self.z) * torch.sum(torch.abs(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l2_l1_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-41e9d5154d7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbest_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2_l1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msubtrain_rmse_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'l2_l1_loss' is not defined"
     ]
    }
   ],
   "source": [
    "h = 90\n",
    "batch_cnt = 0\n",
    "best_step_cnt = 0\n",
    "early_stop = 0\n",
    "best_rmse = math.inf\n",
    "loss_fn = l2_l1_loss(0.5)\n",
    "\n",
    "subtrain_rmse_list = []\n",
    "valid_rmse_list = []\n",
    "    \n",
    "for epoch_id in range(0, nepoch): \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))      \n",
    "        net_d.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer_q5.zero_grad()\n",
    "        outputs = net_d(inputs)        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_q5.step()\n",
    "\n",
    "        batch_cnt += 1\n",
    "        best_step_cnt += 1\n",
    "        if batch_cnt % 100 == 0:\n",
    "            subtrain_pred = net_d(X_subtrain_torch)\n",
    "            subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            valid_pred = net_d(X_valid_torch)\n",
    "            valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "\n",
    "            if valid_rmse < best_rmse:\n",
    "                best_step_cnt = 0\n",
    "                best_rmse = valid_rmse\n",
    "                torch.save(net_d.state_dict(), './net/best_q7_z'+str(0.5)+'.pkl')\n",
    "        if best_step_cnt > 5000:\n",
    "            print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "            print(\"batch cnt while early stop = \", batch_cnt)\n",
    "            early_stop = 1\n",
    "            break\n",
    "    if early_stop == 1:\n",
    "        break\n",
    "print(\"batch cnt =\", batch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(len(subtrain_rmse_list)))\n",
    "plt.plot(l, subtrain_rmse_list, label='subtrain')\n",
    "plt.plot(l, valid_rmse_list, label='valid')\n",
    "plt.xlabel(\"per 100 batch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_d.load_state_dict(torch.load('./net/best_q7_z0.5.pkl'))\n",
    "net_d.eval()\n",
    "test_pred = net_d(X_test_torch)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "print(\"z = 0.5, test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_q7(z):\n",
    "    h = 90\n",
    "    batch_cnt = 0\n",
    "    best_step_cnt = 0\n",
    "    early_stop = 0\n",
    "    best_rmse = math.inf\n",
    "    loss_fn = l2_l1_loss(z)\n",
    "\n",
    "    for epoch_id in range(0, nepoch): \n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))      \n",
    "            net_d.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_q5.zero_grad()\n",
    "            outputs = net_d(inputs)        \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer_q5.step()\n",
    "\n",
    "            batch_cnt += 1\n",
    "            best_step_cnt += 1\n",
    "            if batch_cnt % 100 == 0:\n",
    "                subtrain_pred = net_d(X_subtrain_torch\n",
    "                valid_pred = net_d(X_valid_torch)\n",
    "                valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "\n",
    "                if valid_rmse < best_rmse:\n",
    "                    best_step_cnt = 0\n",
    "                    best_rmse = valid_rmse\n",
    "                    torch.save(net_d.state_dict(), './net/best_q7_z'+str(z)+'.pkl')\n",
    "            if best_step_cnt > 5000:\n",
    "                print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "                print(\"batch cnt while early stop = \", batch_cnt)\n",
    "                early_stop = 1\n",
    "                break\n",
    "        if early_stop == 1:\n",
    "            break\n",
    "    print(\"batch cnt =\", batch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_q7 = [0, 0.1, 0.9, 1]\n",
    "for i in z_q7:\n",
    "    net_d.load_state_dict(torch.load('./net/best_q7_z'+str(i)+'.pkl'))\n",
    "    net_d.eval()\n",
    "    test_pred = net_d(X_test_torch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "    print(\"z = \",i ,\" test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1的計算方式較不能適應各類型況，因此理論上z越接近0的時候，預測效果越差，越接近1效果越好，然而兩種loss function的線性組合，能夠彌補對方的缺點，因此效果通常會好過只用一種loss function，就此題使用的z參數而言，0.9應有最佳的預測效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8 L2 + customized loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "藉由改變z，以改變customized loss 和 L2 loss的比例，可以算出對於此資料集而言，何種線性組合的預測效果較佳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customerized(nn.Module):\n",
    "    def __init__(self, z):\n",
    "        super().__init__()\n",
    "        self.z = z\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return self.z * torch.sum(torch.pow((x - y), 2)) + (1 - self.z) * torch.sum(0.5 * torch.clamp(x - y, min=0.0) + 0.5 * torch.clamp(y - x, min=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 90\n",
    "batch_cnt = 0\n",
    "best_step_cnt = 0\n",
    "early_stop = 0\n",
    "best_rmse = math.inf\n",
    "loss_fn = Customerized(0)\n",
    "\n",
    "subtrain_rmse_list = []\n",
    "valid_rmse_list = []\n",
    "    \n",
    "for epoch_id in range(0, nepoch): \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))      \n",
    "        net_d.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer_q5.zero_grad()\n",
    "        outputs = net_d(inputs)        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_q5.step()\n",
    "\n",
    "        batch_cnt += 1\n",
    "        best_step_cnt += 1\n",
    "        if batch_cnt % 100 == 0:\n",
    "            subtrain_pred = net_d(X_subtrain_torch)\n",
    "            subtrain_rmse = np.sqrt(mean_squared_error(subtrain_pred.detach().numpy(), Y_subtrain_torch))\n",
    "            subtrain_rmse_list.append(subtrain_rmse)\n",
    "            valid_pred = net_d(X_valid_torch)\n",
    "            valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "            valid_rmse_list.append(valid_rmse)\n",
    "\n",
    "            if valid_rmse < best_rmse:\n",
    "                best_step_cnt = 0\n",
    "                best_rmse = valid_rmse\n",
    "                torch.save(net_d.state_dict(), './net/best_q8_z'+str(0)+'.pkl')\n",
    "        if best_step_cnt > 5000:\n",
    "            print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "            print(\"batch cnt while early stop = \", batch_cnt)\n",
    "            early_stop = 1\n",
    "            break\n",
    "    if early_stop == 1:\n",
    "        break\n",
    "print(\"batch cnt =\", batch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(len(subtrain_rmse_list)))\n",
    "plt.plot(l, subtrain_rmse_list, label='subtrain')\n",
    "plt.plot(l, valid_rmse_list, label='valid')\n",
    "plt.xlabel(\"per 100 batch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_d.load_state_dict(torch.load('./net/best_q8_z0.pkl'))\n",
    "net_d.eval()\n",
    "test_pred = net_d(X_test_torch)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "print(\"z = 0, test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_q8(z):\n",
    "    h = 90\n",
    "    batch_cnt = 0\n",
    "    best_step_cnt = 0\n",
    "    early_stop = 0\n",
    "    best_rmse = math.inf\n",
    "    loss_fn = Customerized(0)\n",
    "\n",
    "    for epoch_id in range(0, nepoch): \n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))      \n",
    "            net_d.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer_q5.zero_grad()\n",
    "            outputs = net_d(inputs)        \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer_q5.step()\n",
    "\n",
    "            batch_cnt += 1\n",
    "            best_step_cnt += 1\n",
    "            if batch_cnt % 100 == 0:\n",
    "                subtrain_pred = net_d(X_subtrain_torch)\n",
    "                valid_pred = net_d(X_valid_torch)\n",
    "                valid_rmse = np.sqrt(mean_squared_error(valid_pred.detach().numpy(), Y_valid_torch))\n",
    "\n",
    "\n",
    "                if valid_rmse < best_rmse:\n",
    "                    best_step_cnt = 0\n",
    "                    best_rmse = valid_rmse\n",
    "                    torch.save(net_d.state_dict(), './net/best_q8_z'+str(z)+'.pkl')\n",
    "            if best_step_cnt > 5000:\n",
    "                print(\"best step cnt while early stop = \", best_step_cnt)\n",
    "                print(\"batch cnt while early stop = \", batch_cnt)\n",
    "                early_stop = 1\n",
    "                break\n",
    "        if early_stop == 1:\n",
    "            break\n",
    "    print(\"batch cnt =\", batch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_q8 = [0.1, 0.5, 0.9, 1]\n",
    "for i in z_q8:\n",
    "    net_d.load_state_dict(torch.load('./net/best_q8_z'+str(i)+'.pkl'))\n",
    "    net_d.eval()\n",
    "    test_pred = net_d(X_test_torch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(test_pred.detach().numpy(), Y_test_torch))\n",
    "\n",
    "    print(\"z = \",i ,\" test RMSE = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常兩種loss function的線性組合能夠一定程度的彌補對方的缺點，因此很可能會好過只用一種loss function，而通常效果較好的loss function占比越大效果越好，因此就此題而言最佳預測效果可能發生在z = 0.1或0.9時。而印象中，Customerized loss似乎不太適合本題的資料集，因此預測效果最好的情況落在 z=0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
